{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Segmentation for Medical diagnosis using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torch import optim\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.transforms import transforms\n",
    "from torchinfo import summary\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import pathlib\n",
    "from time import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downlaod the CVC clinic dataset and extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -L -o ~/Downloads/cvcclinicdb.zip\\\n",
    "#   https://www.kaggle.com/api/v1/datasets/download/balraj98/cvcclinicdb\n",
    "# !mkdir data\n",
    "# !unzip ~/Downloads/cvcclinicdb.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./config.json\",\"r\") as f:\n",
    "    config = json.load(f)\n",
    "config\n",
    "image_path = config['data_path']+\"Original/\"\n",
    "mask_path  = config['data_path']+\"Ground Truth/\"\n",
    "images = glob.glob(image_path+\"*\"+config['file_extn'])\n",
    "masks  = glob.glob(mask_path+\"*\"+config['file_extn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CVC custom dataset and pre process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make CVC dataset\n",
    "\"\"\"\n",
    "\n",
    "class CVCDataset(Dataset):\n",
    "    def __init__(self, images, image_transforms=None, mask_transforms=None):\n",
    "        super(CVCDataset, self).__init__()\n",
    "        self.images = images\n",
    "        self.image_transforms = image_transforms\n",
    "        self.mask_transforms = mask_transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        img_split = img_path.split('/')\n",
    "        img_name = img_split[-1]\n",
    "        img_dir = '/'.join(img_split[:-2])\n",
    "        mask_path = img_dir+\"/Ground Truth/\"+img_name\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if self.image_transforms:\n",
    "            image = self.image_transforms(image)\n",
    "        if self.mask_transforms:\n",
    "            mask = self.mask_transforms(mask)\n",
    "        # inv_mask = 1 - mask\n",
    "        # mask = torch.concat([inv_mask, mask], dim=0)\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transform to threshold the mask\n",
    "\n",
    "class ThresholdTransform(object):\n",
    "  def __init__(self, thr=0.5):\n",
    "    self.thr = thr\n",
    "\n",
    "  def __call__(self, x):\n",
    "    return (x > self.thr).to(x.dtype)  # do not change the data type\n",
    "\n",
    "\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((256, 256)),\n",
    "    #transforms.Normalize()\n",
    "])\n",
    "\n",
    "mask_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((256, 256)),\n",
    "    ThresholdTransform()\n",
    "])\n",
    "\n",
    "imgset = CVCDataset(images, image_transforms, mask_transforms)\n",
    "trainset, testset = random_split(imgset, [0.9, 0.1])\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(testset, batch_size=8, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check image and mask sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, mask = next(iter(train_loader))\n",
    "data = torch.einsum(\"chw->hwc\", data[0])\n",
    "mask = torch.einsum(\"chw->hwc\", mask[0])\n",
    "# mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Parts of the U-Net model \"\"\"\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(conv => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\" Downscaling with maxpool \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Down,self).__init__()\n",
    "        self.down = nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.down(x)\n",
    "\n",
    "\n",
    "class DownDoubleConv(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DownDoubleConv, self).__init__()\n",
    "        self.down_doubleconv = nn.Sequential(\n",
    "            Down(),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.down_doubleconv(x)\n",
    "\n",
    "\n",
    "class UpDoubleConv(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super(UpDoubleConv, self).__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.double_conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is BCHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False, checkpointing=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        self.checkpointing = checkpointing\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (DownDoubleConv(64, 128))\n",
    "        self.down2 = (DownDoubleConv(128, 256))\n",
    "        self.down3 = (DownDoubleConv(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (DownDoubleConv(512, 1024 // factor))\n",
    "        self.up1 = (UpDoubleConv(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (UpDoubleConv(512, 256 // factor, bilinear))\n",
    "        self.up3 = (UpDoubleConv(256, 128 // factor, bilinear))\n",
    "        self.up4 = (UpDoubleConv(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, n_classes))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.checkpointing:\n",
    "            x1 = checkpoint(self.inc, x, use_reentrant=False)\n",
    "            x2 = checkpoint(self.down1, x1, use_reentrant=False)\n",
    "            x3 = checkpoint(self.down2, x2, use_reentrant=False)\n",
    "            x4 = checkpoint(self.down3, x3, use_reentrant=False)\n",
    "            x5 = checkpoint(self.down4, x4, use_reentrant=False)\n",
    "            x = checkpoint(self.up1, x5,x4, use_reentrant=False)\n",
    "            x = checkpoint(self.up2, x,x3, use_reentrant=False)\n",
    "            x = checkpoint(self.up3, x,x2, use_reentrant=False)\n",
    "            x = checkpoint(self.up4, x,x1, use_reentrant=False)\n",
    "            logits = checkpoint(self.outc, x, use_reentrant=False)\n",
    "            # probs = checkpoint(self.sigmoid, logits, use_reentrant=False)\n",
    "            return logits\n",
    "\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# test_input, ground_truth = next(iter(train_loader))\n",
    "# test_input = test_input.to(device)\n",
    "# # test_input = torch.einsum(\"bchw->bhwc\", test_input)\n",
    "# ground_truth = torch.einsum(\"bchw->bhwc\", ground_truth)\n",
    "# plt.imshow(ground_truth[0], cmap='gray')\n",
    "# test_model = UNet(3,1,checkpointing=True).to(device)\n",
    "# test_output = test_model(test_input)\n",
    "# test_output = torch.einsum(\"bchw->bhwc\", test_output.detach().cpu())\n",
    "# test_output_bin = (test_output > 0.5).to(test_output.dtype)\n",
    "# plt.imshow(test_output[0], cmap='gray')\n",
    "# plt.imshow(test_output_bin[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test model\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# test_input = torch.randn((16, 3, 256, 256)).to(device)\n",
    "# test_model = UNet(3,2,checkpointing=True).to(device)\n",
    "# print(summary(test_model))\n",
    "# torch.cuda.reset_peak_memory_stats()\n",
    "# test_out = test_model(test_input)\n",
    "# print(f\"Peak Memory Usage With Checkpointing: {torch.cuda.max_memory_allocated()/1e6} MB\")\n",
    "# print(test_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plots(losses, name=None):\n",
    "    pathlib.Path(\"results\").mkdir(parents=True, exist_ok=True)\n",
    "    if not name:\n",
    "        timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        save_plot_path = \"results/plot-\"+timestr\n",
    "    else:\n",
    "        save_plot_path = \"results/\"+name\n",
    "    epochs = len(losses['train_loss'])\n",
    "    plt.plot(range(1,epochs+1), losses['train_loss'], label='Train loss')\n",
    "    plt.plot(range(1,epochs+1), losses['val_loss'], label='Validation loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title(f\"Losses\")\n",
    "    plt.savefig(save_plot_path, facecolor='w', edgecolor='none')\n",
    "    plt.show()\n",
    "\n",
    "def save_model(model, name=None):\n",
    "    pathlib.Path(\"results/saved_models\").mkdir(parents=True, exist_ok=True)\n",
    "    if not name:\n",
    "        timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        save_model_path = \"results/saved_models/\"+timestr+\".pth\"\n",
    "    else:\n",
    "        save_model_path = \"results/saved_models/\"+name+\".pth\"\n",
    "    torch.save(model.state_dict(), save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define custom IOU metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IoU metric\n",
    "\n",
    "def custom_iou(predictions: torch.tensor, targets: torch.tensor):\n",
    "    # inputs are of shape BxCxHxW\n",
    "    assert isinstance(predictions, torch.Tensor), \"Not a torch tensor\"\n",
    "    assert isinstance(targets, torch.Tensor), \"Not a torch tensor\"\n",
    "    smooth = 1e-6\n",
    "    n_channels = predictions.shape[1]\n",
    "    predictions = F.sigmoid(predictions) if n_channels == 1 else F.softmax(predictions, dim=1)\n",
    "    # intersection : element wise multiplication or logical AND\n",
    "    intersection = torch.logical_and(predictions, targets).float().sum((1,2,3))\n",
    "    # union : element wise sum or logical OR\n",
    "    union = torch.logical_or(predictions, targets).float().sum((1,2,3))\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    return iou.mean()\n",
    "\n",
    "\"\"\"\n",
    "dice metric\n",
    "dice_coeff = [2 * intersection(A,B)] / [sum of areas of A and B]\n",
    "Intersection can be expressed as multiplication. Dice coeff is differentiable and\n",
    "can be part of the loss function.\n",
    "\"\"\" \n",
    "def custom_dice(predictions: torch.tensor, targets: torch.tensor):\n",
    "    # inputs are of shape BxCxHxW\n",
    "    # return dice loss, to be used in loss function\n",
    "    assert isinstance(predictions, torch.Tensor), \"Not a torch tensor\"\n",
    "    assert isinstance(targets, torch.Tensor), \"Not a torch tensor\"\n",
    "    smooth = 1e-6\n",
    "    n_channels = predictions.shape[1]\n",
    "    predictions = F.sigmoid(predictions) if n_channels == 1 else F.softmax(predictions, dim=1)\n",
    "    intersection = (2 * predictions * targets).float().sum((1,2,3))\n",
    "    total = predictions.sum((1,2,3)) + targets.sum((1,2,3))\n",
    "    dice_coeffs = (intersection + smooth) / (total + smooth)\n",
    "    return 1 - dice_coeffs.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, train_loader, loss_criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    total = 0\n",
    "    total_iou = 0\n",
    "    n_train = len(train_loader.dataset)\n",
    "    with tqdm(total=n_train, desc=f'Epoch {epoch}', unit='img') as pbar:\n",
    "        for batchidx, (data, target) in enumerate(train_loader):\n",
    "            #print(f'batch id: {batchidx}')\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            grad_scaler = torch.amp.GradScaler(enabled=True)\n",
    "            with torch.autocast(device_type=device.type):\n",
    "                output = model(data)\n",
    "                loss = loss_criterion(output, target)\n",
    "                loss += custom_dice(output, target)\n",
    "                train_loss += loss.item()\n",
    "            grad_scaler.scale(loss).backward() # loss.backward()\n",
    "            grad_scaler.step(optimizer) # optimizer.step()\n",
    "            grad_scaler.update()\n",
    "            predictions = nn.functional.sigmoid(output)\n",
    "            predictions = (predictions > 0.5).to(predictions.dtype)\n",
    "            iou = custom_iou(output, target)\n",
    "            total_iou += iou.item()\n",
    "            total += len(data)\n",
    "            pbar.update(len(data))\n",
    "        avg_iou = total_iou/len(train_loader)\n",
    "        avg_loss = train_loss/total\n",
    "        pbar.set_postfix({'avg_loss (epoch)': avg_loss, 'IoU': avg_iou})\n",
    "        # print(f\"Train epoch: {epoch} [{(batchidx+1) * len(data)}/{len(train_loader.dataset)}\\\n",
    "        #   ({(100. * batchidx/len(train_loader)):.0f}%)]\\tLoss: {avg_loss:.6f}\\tIoU: {avg_iou:.6f}\")\n",
    "    return avg_iou, avg_loss\n",
    "\n",
    "def test_model(model, device, test_loader, loss_criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    total_iou = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_criterion(output, target).item()\n",
    "            predictions = nn.functional.sigmoid(output)\n",
    "            predictions = (output > 0.5).to(predictions.dtype)\n",
    "            iou = custom_iou(output, target)\n",
    "            total_iou += iou.item()\n",
    "            total += len(data)\n",
    "    test_loss /= total\n",
    "    test_iou = total_iou/len(test_loader)\n",
    "    print(f\"Test set: Average loss: {test_loss:.4f}, IoU: {test_iou:.6f})\")\n",
    "    return test_iou, test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 100\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "loss_criterion = nn.BCEWithLogitsLoss() # nn.BCELoss()\n",
    "inp_channels = 3\n",
    "model = UNet(inp_channels, num_classes, checkpointing=True).to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "losses = defaultdict(list)\n",
    "\n",
    "print(f\"using device: {device}\")\n",
    "# print(summary(model))\n",
    "n_train = len(train_loader.dataset)\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    _, tloss = train_model(model, device, train_loader, loss_criterion, optimizer, epoch)\n",
    "    losses['train_loss'].append(tloss)\n",
    "    _, vloss = test_model(model, device, test_loader, loss_criterion)\n",
    "    losses['val_loss'].append(vloss)\n",
    "\n",
    "# save plots\n",
    "save_plots(losses, 'mnist-loss')\n",
    "\n",
    "#save model\n",
    "save_model(model, 'mnist_sample_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input, ground_truth = next(iter(train_loader))\n",
    "test_input = test_input.to(device)\n",
    "# ground_truth = torch.einsum(\"bchw->bhwc\", ground_truth)\n",
    "test_output = model(test_input)\n",
    "test_ip = torch.einsum(\"bchw->bhwc\", test_input).detach().cpu()\n",
    "test_output = nn.functional.sigmoid(test_output)\n",
    "# test_output_bg = test_output[:,0,:,:].to(test_output.dtype)\n",
    "test_output_tumor = test_output[:,0,:,:].to(test_output.dtype)\n",
    "# test_output = torch.einsum(\"bchw->bhwc\", test_output.detach().cpu())\n",
    "# test_output_bg = test_output_bg.detach().cpu()\n",
    "test_output_tumor = test_output_tumor.detach().cpu()\n",
    "\n",
    "fig, axs = plt.subplots(1,3)\n",
    "idx = 10\n",
    "axs[0].imshow(test_ip[idx])\n",
    "axs[1].imshow(ground_truth[idx,0,:,:], cmap='gray')\n",
    "axs[2].imshow(test_output_tumor[idx,:,:], cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "UNET++.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
