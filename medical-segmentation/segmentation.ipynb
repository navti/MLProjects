{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Segmentation for Medical diagnosis using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import cv2\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.transforms import transforms\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downlaod the CVC clinic dataset and extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -L -o ~/Downloads/cvcclinicdb.zip\\\n",
    "#   https://www.kaggle.com/api/v1/datasets/download/balraj98/cvcclinicdb\n",
    "# !mkdir data\n",
    "# !unzip ~/Downloads/cvcclinicdb.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./config.json\",\"r\") as f:\n",
    "    config = json.load(f)\n",
    "config\n",
    "image_path = config['data_path']+\"Original/\"\n",
    "mask_path  = config['data_path']+\"Ground Truth/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob(image_path+\"*\"+config['file_extn'])\n",
    "masks  = glob.glob(mask_path+\"*\"+config['file_extn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CVC custom dataset and pre process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make CVC dataset\n",
    "\"\"\"\n",
    "\n",
    "class CVCDataset(Dataset):\n",
    "    def __init__(self, images, transform=None):\n",
    "        super(CVCDataset, self).__init__()\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        img_split = img_path.split('/')\n",
    "        img_name = img_split[-1]\n",
    "        img_dir = '/'.join(img_split[:-2])\n",
    "        mask_path = img_dir+\"/Ground Truth/\"+img_name\n",
    "        image = cv2.imread(img_path)\n",
    "        mask = cv2.imread(mask_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize()\n",
    "])\n",
    "\n",
    "mask_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "imgset = CVCDataset(images, image_transforms)\n",
    "trainset, testset = random_split(imgset, [0.9, 0.1])\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Parts of the U-Net model \"\"\"\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(conv => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\" Downscaling with maxpool \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Down,self).__init__()\n",
    "        self.down = nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.down(x)\n",
    "\n",
    "\n",
    "class DownDoubleConv(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DownDoubleConv, self).__init__()\n",
    "        self.down_doubleconv = nn.Sequential(\n",
    "            Down(),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.down_doubleconv(x)\n",
    "\n",
    "\n",
    "class UpDoubleConv(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super(UpDoubleConv, self).__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.double_conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is BCHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False, checkpointing=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        self.checkpointing = checkpointing\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (DownDoubleConv(64, 128))\n",
    "        self.down2 = (DownDoubleConv(128, 256))\n",
    "        self.down3 = (DownDoubleConv(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (DownDoubleConv(512, 1024 // factor))\n",
    "        self.up1 = (UpDoubleConv(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (UpDoubleConv(512, 256 // factor, bilinear))\n",
    "        self.up3 = (UpDoubleConv(256, 128 // factor, bilinear))\n",
    "        self.up4 = (UpDoubleConv(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.checkpointing:\n",
    "            x1 = checkpoint(self.inc, x)\n",
    "            x2 = checkpoint(self.down1, x1)\n",
    "            x3 = checkpoint(self.down2, x2)\n",
    "            x4 = checkpoint(self.down3, x3)\n",
    "            x5 = checkpoint(self.down4, x4)\n",
    "            x = checkpoint(self.up1, x5,x4)\n",
    "            x = checkpoint(self.up2, x,x3)\n",
    "            x = checkpoint(self.up3, x,x2)\n",
    "            x = checkpoint(self.up4, x,x1)\n",
    "            logits = checkpoint(self.outc, x)\n",
    "            return logits\n",
    "\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "UNet                                          --\n",
      "├─DoubleConv: 1-1                             --\n",
      "│    └─Sequential: 2-1                        --\n",
      "│    │    └─Conv2d: 3-1                       1,728\n",
      "│    │    └─BatchNorm2d: 3-2                  128\n",
      "│    │    └─ReLU: 3-3                         --\n",
      "│    │    └─Conv2d: 3-4                       36,864\n",
      "│    │    └─BatchNorm2d: 3-5                  128\n",
      "│    │    └─ReLU: 3-6                         --\n",
      "├─DownDoubleConv: 1-2                         --\n",
      "│    └─Sequential: 2-2                        --\n",
      "│    │    └─Down: 3-7                         --\n",
      "│    │    └─DoubleConv: 3-8                   221,696\n",
      "├─DownDoubleConv: 1-3                         --\n",
      "│    └─Sequential: 2-3                        --\n",
      "│    │    └─Down: 3-9                         --\n",
      "│    │    └─DoubleConv: 3-10                  885,760\n",
      "├─DownDoubleConv: 1-4                         --\n",
      "│    └─Sequential: 2-4                        --\n",
      "│    │    └─Down: 3-11                        --\n",
      "│    │    └─DoubleConv: 3-12                  3,540,992\n",
      "├─DownDoubleConv: 1-5                         --\n",
      "│    └─Sequential: 2-5                        --\n",
      "│    │    └─Down: 3-13                        --\n",
      "│    │    └─DoubleConv: 3-14                  14,159,872\n",
      "├─UpDoubleConv: 1-6                           --\n",
      "│    └─ConvTranspose2d: 2-6                   2,097,664\n",
      "│    └─DoubleConv: 2-7                        --\n",
      "│    │    └─Sequential: 3-15                  7,079,936\n",
      "├─UpDoubleConv: 1-7                           --\n",
      "│    └─ConvTranspose2d: 2-8                   524,544\n",
      "│    └─DoubleConv: 2-9                        --\n",
      "│    │    └─Sequential: 3-16                  1,770,496\n",
      "├─UpDoubleConv: 1-8                           --\n",
      "│    └─ConvTranspose2d: 2-10                  131,200\n",
      "│    └─DoubleConv: 2-11                       --\n",
      "│    │    └─Sequential: 3-17                  442,880\n",
      "├─UpDoubleConv: 1-9                           --\n",
      "│    └─ConvTranspose2d: 2-12                  32,832\n",
      "│    └─DoubleConv: 2-13                       --\n",
      "│    │    └─Sequential: 3-18                  110,848\n",
      "├─OutConv: 1-10                               --\n",
      "│    └─Conv2d: 2-14                           65\n",
      "======================================================================\n",
      "Total params: 31,037,633\n",
      "Trainable params: 31,037,633\n",
      "Non-trainable params: 0\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codez/anaconda3/envs/mlenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/codez/anaconda3/envs/mlenv/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak Memory Usage With Checkpointing: 9236.502016 MB\n",
      "torch.Size([64, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test_input = torch.randn((64, 3, 256, 256)).to(device)\n",
    "test_model = UNet(3,1,checkpointing=True).to(device)\n",
    "print(summary(test_model))\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "test_out = test_model(test_input)\n",
    "print(f\"Peak Memory Usage With Checkpointing: {torch.cuda.max_memory_allocated()/1e6} MB\")\n",
    "print(test_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BCHW\n",
    "im1 = torch.randn(64,3,10,14)\n",
    "im1 = F.pad(im1, [1,1,2,2])\n",
    "im1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "UNET++.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
